---
# Prometheus Namespace (for monitoring stack)
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
  labels:
    name: monitoring

---
# Prometheus ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      external_labels:
        cluster: crypto-analytics
        environment: production

    # Alertmanager configuration
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          - alertmanager:9093

    # Rule files
    rule_files:
      - '/etc/prometheus/rules/alert-rules.yml'

    scrape_configs:
      # Prometheus self-monitoring
      - job_name: 'prometheus'
        static_configs:
        - targets: ['localhost:9090']

      # Kubernetes API server
      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
          action: keep
          regex: default;kubernetes;https

      # Kubelet metrics
      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
        - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

      # Pod metrics via cAdvisor
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
        - role: pod
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: 'true'
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__

      # Service endpoints in crypto namespace
      - job_name: 'kubernetes-services'
        kubernetes_sd_configs:
        - role: service
          namespaces:
            names:
            - crypto
        metrics_path: /metrics
        relabel_configs:
        - source_labels: [__meta_kubernetes_service_label_monitoring]
          action: keep
          regex: 'true'
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name]
          action: replace
          target_label: job
          regex: (.+);(.+)
          replacement: $1/$2

      # Node exporter
      - job_name: 'node-exporter'
        kubernetes_sd_configs:
        - role: endpoints
          namespaces:
            names:
            - monitoring
        relabel_configs:
        - source_labels: [__meta_kubernetes_service_label_app]
          action: keep
          regex: node-exporter

---
# Alert Rules
apiVersion: v1
kind: ConfigMap
metadata:
  name: alert-rules
  namespace: monitoring
data:
  alert-rules.yml: |
    groups:
    - name: crypto-services
      interval: 30s
      rules:
      # Service availability alerts
      - alert: ServiceDown
        expr: up{job=~".*-service"} == 0
        for: 2m
        labels:
          severity: critical
          component: service
        annotations:
          summary: "{{ $labels.job }} service is down"
          description: "{{ $labels.job }} has been unavailable for 2 minutes (instance: {{ $labels.instance }})"

      # CPU alerts
      - alert: HighCPUUsage
        expr: |
          rate(container_cpu_usage_seconds_total{namespace="crypto",pod!=""}[5m]) > 0.8
        for: 5m
        labels:
          severity: warning
          component: resource
        annotations:
          summary: "High CPU usage on {{ $labels.pod }}"
          description: "Pod {{ $labels.pod }} CPU usage is {{ $value | humanizePercentage }}"

      - alert: CriticalCPUUsage
        expr: |
          rate(container_cpu_usage_seconds_total{namespace="crypto",pod!=""}[5m]) > 0.95
        for: 2m
        labels:
          severity: critical
          component: resource
        annotations:
          summary: "Critical CPU usage on {{ $labels.pod }}"
          description: "Pod {{ $labels.pod }} CPU usage is {{ $value | humanizePercentage }}"

      # Memory alerts
      - alert: HighMemoryUsage
        expr: |
          container_memory_usage_bytes{namespace="crypto",pod!=""} / 
          container_spec_memory_limit_bytes{namespace="crypto",pod!=""} > 0.9
        for: 5m
        labels:
          severity: warning
          component: resource
        annotations:
          summary: "High memory usage on {{ $labels.pod }}"
          description: "Pod {{ $labels.pod }} memory usage is {{ $value | humanizePercentage }}"

      - alert: OutOfMemory
        expr: |
          container_memory_usage_bytes{namespace="crypto",pod!=""} / 
          container_spec_memory_limit_bytes{namespace="crypto",pod!=""} > 0.95
        for: 2m
        labels:
          severity: critical
          component: resource
        annotations:
          summary: "Pod {{ $labels.pod }} running out of memory"
          description: "Pod {{ $labels.pod }} memory usage is {{ $value | humanizePercentage }}"

      # Pod restart alerts
      - alert: PodRestartingTooOften
        expr: |
          rate(kube_pod_container_status_restarts_total{namespace="crypto"}[15m]) > 0
        for: 5m
        labels:
          severity: warning
          component: pod
        annotations:
          summary: "Pod {{ $labels.pod }} restarting frequently"
          description: "Pod {{ $labels.pod }} has restarted {{ $value | humanize }} times in 15 minutes"

      # Network errors
      - alert: HighHTTPErrorRate
        expr: |
          rate(http_requests_total{status=~"5..",namespace="crypto"}[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
          component: http
        annotations:
          summary: "High HTTP error rate on {{ $labels.service }}"
          description: "HTTP 5xx error rate is {{ $value | humanizePercentage }}"

      # Database connectivity
      - alert: DatabaseConnectionPoolExhausted
        expr: |
          (pg_stat_activity_count / pg_settings_max_connections) > 0.8
        for: 5m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "Database connection pool nearly exhausted"
          description: "Database connection usage is {{ $value | humanizePercentage }}"

      # Kafka broker issues
      - alert: KafkaBrokerDown
        expr: kafka_server_replica_manager_value{topic!=""} == 0
        for: 2m
        labels:
          severity: critical
          component: kafka
        annotations:
          summary: "Kafka broker down"
          description: "Kafka broker {{ $labels.broker_id }} is down"

      - alert: KafkaHighUnderReplicatedPartitions
        expr: kafka_controller_KafkaController_underReplicatedPartitions > 0
        for: 5m
        labels:
          severity: warning
          component: kafka
        annotations:
          summary: "Kafka has under-replicated partitions"
          description: "{{ $value }} partitions are under-replicated"

      # Response time alerts
      - alert: SlowAPI
        expr: |
          histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{service="api-gateway"}[5m])) > 1
        for: 5m
        labels:
          severity: warning
          component: performance
        annotations:
          summary: "API gateway 99th percentile latency high"
          description: "API gateway 99th percentile latency is {{ $value | humanizeDuration }}"

      # Queue depth alerts
      - alert: KafkaQueueDepth
        expr: kafka_log_log_size > 1000000000
        for: 10m
        labels:
          severity: warning
          component: kafka
        annotations:
          summary: "Kafka queue depth getting large"
          description: "Partition has {{ $value | humanize }} bytes backlog"

      # Storage alerts
      - alert: PersistentVolumeUsage
        expr: |
          (kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes) > 0.85
        for: 5m
        labels:
          severity: warning
          component: storage
        annotations:
          summary: "PersistentVolume {{ $labels.persistentvolumeclaim }} usage high"
          description: "Volume usage is {{ $value | humanizePercentage }}"

---
# Alertmanager Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
data:
  alertmanager.yml: |
    global:
      resolve_timeout: 5m
      slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'

    route:
      receiver: 'default'
      group_by: ['alertname', 'cluster']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      routes:
      - match:
          severity: critical
        receiver: 'critical'
        repeat_interval: 5m
      - match:
          severity: warning
        receiver: 'warnings'

    receivers:
    - name: 'default'
      slack_configs:
      - channel: '#crypto-alerts'
        title: 'Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

    - name: 'critical'
      slack_configs:
      - channel: '#crypto-critical'
        title: 'üö® CRITICAL: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

    - name: 'warnings'
      slack_configs:
      - channel: '#crypto-warnings'
        title: '‚ö†Ô∏è WARNING: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

---
# Prometheus Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
spec:
  replicas: 2
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: prometheus
      containers:
      - name: prometheus
        image: prom/prometheus:latest
        args:
          - '--config.file=/etc/prometheus/prometheus.yml'
          - '--storage.tsdb.path=/prometheus'
          - '--storage.tsdb.retention.time=30d'
          - '--web.enable-lifecycle'
        ports:
        - containerPort: 9090
        volumeMounts:
        - name: prometheus-config
          mountPath: /etc/prometheus
        - name: prometheus-rules
          mountPath: /etc/prometheus/rules
        - name: prometheus-storage
          mountPath: /prometheus
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 2000m
            memory: 2Gi
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9090
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: prometheus-config
        configMap:
          name: prometheus-config
      - name: prometheus-rules
        configMap:
          name: alert-rules
      - name: prometheus-storage
        emptyDir: {}

---
# Prometheus Service
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: monitoring
spec:
  selector:
    app: prometheus
  ports:
  - port: 9090
    targetPort: 9090
  type: ClusterIP

---
# Alertmanager Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: monitoring
spec:
  replicas: 3
  selector:
    matchLabels:
      app: alertmanager
  template:
    metadata:
      labels:
        app: alertmanager
    spec:
      containers:
      - name: alertmanager
        image: prom/alertmanager:latest
        args:
          - '--config.file=/etc/alertmanager/alertmanager.yml'
          - '--storage.path=/alertmanager'
        ports:
        - containerPort: 9093
        volumeMounts:
        - name: alertmanager-config
          mountPath: /etc/alertmanager
        - name: alertmanager-storage
          mountPath: /alertmanager
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
      volumes:
      - name: alertmanager-config
        configMap:
          name: alertmanager-config
      - name: alertmanager-storage
        emptyDir: {}

---
# Alertmanager Service
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: monitoring
spec:
  selector:
    app: alertmanager
  ports:
  - port: 9093
    targetPort: 9093
  type: ClusterIP

---
# ServiceAccount for Prometheus
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: monitoring

---
# ClusterRole for Prometheus
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups: ["extensions"]
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]

---
# ClusterRoleBinding for Prometheus
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: monitoring
